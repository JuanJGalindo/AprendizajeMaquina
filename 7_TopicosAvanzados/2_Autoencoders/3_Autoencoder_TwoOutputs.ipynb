{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhHr9rz+N+IjUV7NdwPNYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalvarezme/AprendizajeMaquina/blob/main/7_TopicosAvanzados/2_Autoencoders/3_Autoencoder_TwoOutputs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArFhHj3KY3qO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load and prepare the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()#fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "\n",
        "# create training, validation, and testing sets\n",
        "x_val = x_train[50000:]\n",
        "y_val = y_train[50000:]\n",
        "x_train = x_train[:50000]\n",
        "y_train = y_train[:50000]\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_val = x_val[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,x_val.shape,x_test.shape,y_train.shape,y_val.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "Ci4jpyZ8ZxER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plot original images vs reconstructed images\n",
        "def plot_mnist_autoencoder(x,xpred,cmap='gray',vmin=0,vmax=1):\n",
        "  fig,ax = plt.subplots(2,x.shape[0],figsize=(8,1))\n",
        "  for i,class_ in enumerate(range(x.shape[0])):\n",
        "        ax[0,i].imshow(x[i],cmap=cmap,vmin=vmin,vmax=vmax)\n",
        "        ax[0,i].set_xticks([])\n",
        "        ax[0,i].set_yticks([])\n",
        "\n",
        "        ax[1,i].imshow(xpred[i],cmap=cmap,vmin=vmin,vmax=vmax)\n",
        "        ax[1,i].set_xticks([])\n",
        "        ax[1,i].set_yticks([])\n",
        "  plt.show()\n",
        "  return\n",
        "\n",
        "plot_mnist_autoencoder(x_train[:15],x_train[:15])"
      ],
      "metadata": {
        "id": "Zy5XHmLIZ2hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "#plot images on latent space\n",
        "def plot_mnist_2d(Z,y,images,img_w=28,img_h=28,zoom=0.5,cmap='jet'):\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    plt.axis('off')\n",
        "    for i in range(Z.shape[0]):\n",
        "        #print('img',i+1,'/',Z.shape[0])\n",
        "        image = images[i].reshape((img_w, img_h))\n",
        "        im = OffsetImage(image, zoom=zoom,cmap=cmap)\n",
        "        ab = AnnotationBbox(im, (Z[i,0], Z[i,1]), xycoords='data', frameon=False)\n",
        "        ax.add_artist(ab)\n",
        "        ax.update_datalim([(Z[i,0], Z[i,1])])\n",
        "        ax.autoscale()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "N7-0eUO8Z5jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#traditional PCA algorithm\n",
        "red = PCA(n_components=2, random_state=123)\n",
        "Z = red.fit_transform(x_train.reshape(x_train.shape[0],-1))\n",
        "N = 500\n",
        "plot_mnist_2d(Z[:N],y_train[:N],x_train[:N],img_w=28,img_h=28,zoom=0.3,cmap='gray')"
      ],
      "metadata": {
        "id": "rRKQyjxAZ8CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss object and the optimizer\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Define the autoencoder model\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "xe = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2DTranspose(8, (3, 3), activation='relu', padding='same')(xe)\n",
        "x = Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)\n",
        "reconstructed_img = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Classification branch\n",
        "x = Flatten(name='fencoded')(xe)\n",
        "classification_output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Define the model with two outputs\n",
        "autoencoder = Model(inputs=input_img, outputs=[reconstructed_img, classification_output])\n",
        "\n",
        "autoencoder.summary()\n",
        "tf.keras.utils.plot_model(autoencoder)"
      ],
      "metadata": {
        "id": "q_S_lr4QZmjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom loss function\n",
        "def custom_loss(lambda_=0.5):\n",
        "    def custom_loss_autoencoder(y_true, y_pred):\n",
        "        reconstruction_loss = MeanSquaredError()(y_true[0], y_pred[0])\n",
        "        classification_loss = SparseCategoricalCrossentropy()(y_true[1], y_pred[1])\n",
        "        return lambda_*reconstruction_loss + (1-lambda_)*classification_loss\n",
        "    return custom_loss_autoencoder\n",
        "# Compile the model\n",
        "lam_ = 0.25 #reconstruction error weight\n",
        "autoencoder.compile(optimizer=Adam(), loss=custom_loss(lambda_=lam_))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "monQuofBbTTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom training loop\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "N = 500\n",
        "red = PCA(n_components=2, random_state=123)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    for x_batch, y_batch in tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024).batch(batch_size):\n",
        "        with tf.GradientTape() as tape:\n",
        "            reconstruction, classification = autoencoder(x_batch, training=True)\n",
        "            loss = autoencoder.loss([x_batch, y_batch], [reconstruction, classification])\n",
        "            gradients = tape.gradient(loss, autoencoder.trainable_variables)\n",
        "        autoencoder.optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))\n",
        "\n",
        "    #val\n",
        "    loss_ = []\n",
        "    for x_val_batch, y_val_batch in tf.data.Dataset.from_tensor_slices((x_val, y_val)).shuffle(buffer_size=128).batch(batch_size):\n",
        "        val_reconstruction, val_classification = autoencoder(x_val_batch, training=False)\n",
        "        loss_.append(autoencoder.loss([x_val_batch, y_val_batch], [val_reconstruction, val_classification]))\n",
        "    print(f'Loss: {loss.numpy()} Val_loss: {np.array(loss_).mean()}')\n",
        "    if (epoch+1)%5 == 0:\n",
        "      # Test the model\n",
        "      #plot reconstruction\n",
        "      plot_mnist_autoencoder(x_val_batch,val_reconstruction)\n",
        "      #plot encoded space\n",
        "      encoder_ = tf.keras.Model(inputs=autoencoder.inputs,outputs=autoencoder.get_layer('fencoded').output)\n",
        "      Z = red.fit_transform(encoder_(x_val))\n",
        "\n",
        "      plot_mnist_2d(Z[:N],y_val[:N],x_val[:N],img_w=28,img_h=28,zoom=0.3,cmap='gray')\n",
        "\n",
        "\n",
        "\n",
        "print('done')"
      ],
      "metadata": {
        "id": "Ad5tqyHacAvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZczebgpFeR38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}