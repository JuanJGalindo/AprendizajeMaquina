{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalvarezme/AprendizajeMaquina/blob/main/PriKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Theoretic Learning for Data Upsampling\n",
        "\n",
        "![mutualInfor](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*sHASwCjxy-Tsr3eaDTeHXw.png?raw=1)"
      ],
      "metadata": {
        "id": "0UIesv2RL5xS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Mutual Information, Entropy, Information](https://medium.com/swlh/a-deep-conceptual-guide-to-mutual-information-a5021031fad0)\n",
        "\n",
        "$$I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X) = H(X) + H(Y) - H(X,Y) = H(X,Y) - H(X|Y) - H(Y|X)$$\n",
        "\n",
        "\n",
        "$$H(X) = \\mathbb{E}_{p(x)}\\{I(p(x))\\} = \\mathbb{E}_{p(x)}\\left\\{\\log{\\left(\\frac{1}{p(x)}\\right)}\\right\\} $$"
      ],
      "metadata": {
        "id": "HjulbZkhMsFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principle of Relevant Information\n",
        "\n",
        "## Information Bottleneck\n",
        "\n",
        "Find a reduced representation $\\tilde{X}$ of $X$ founded on the conditional distribution $p(\\tilde{X}|X)$ that preserves the information of $X$ w.r.t. to $Y$:\n",
        "\n",
        "$$\\min_{p(\\tilde{X}|X)} I(\\tilde{X},X)-\\beta I(\\tilde{X},Y)$$\n",
        "\n",
        "$\\beta \\in \\mathbb{R}^+$, $\\tilde{X}\\in\\mathbb{R}^{M \\times P}$, ${X}\\in\\mathbb{R}^{N \\times P}$, $M < N$\n",
        "\n",
        "## Compression/Clustering based on PRI\n",
        "\n",
        "$$\\boxed{\\min_{\\tilde{X}} H(\\tilde{X})+\\lambda D(\\tilde{X}||X)}$$\n",
        "\n",
        "$\\lambda\\in\\mathbb{R}^+$\n",
        "\n",
        "\n",
        "Fixing $H$ as the quadratic Renyi's entropy and $D$ as the Cauchy Swartz divergence:\n",
        "\n",
        "\n",
        "$H_\\alpha(X) = \\frac{1}{1-\\alpha}\\log\\left(\\int_{x\\in X} p^\\alpha (x)dx\\right)$\n",
        "\n",
        "$H_2(X) = -\\log\\left(\\int_{x\\in X} p^2 (x)dx\\right)$\n",
        "\n",
        "\n",
        "$D_{CS}(f||g) = -\\log\\left(\\frac{\\left(\\int f(x)g(x)dx\\right)^2}{\\int f^2(x)dx \\int g^2(x)dx}\\right)$\n",
        "\n",
        "\n",
        "$D_{CS}(f||g) = -\\log\\left(\\left(\\int f(x)g(x)dx\\right)^2\\right) + \\log\\left(\\int f^2(x)dx\\right) + \\log\\left(\\int g^2(x)dx\\right)$\n",
        "\n",
        "$D_{CS}(f||g) = 2 H_{CS}(f;g)-H_2(f)-H_2(g)$\n",
        "\n",
        "$H_{CS}(f;g)=-\\log\\left(\\int f(x)g(x)dx\\right)$: Cauchy Swartz cross-entropy (NOT JOINT entropy)\n"
      ],
      "metadata": {
        "id": "bAml9uZTEdjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Gaussian Kernel-based pdf Parzen Estimator\n",
        "\n",
        "https://medium.com/@cagriaydogdu2334/pdf-estimation-with-parzen-window-a32f3bfffd4c\n",
        "\n",
        "https://milania.de/blog/Introduction_to_kernel_density_estimation_(Parzen_window_method)\n",
        "\n",
        "\n",
        "Given the set $\\{x_n\\in\\mathbb{R}^P\\}_{n=1}^N$\n",
        "\n",
        "$\\hat{p}(x) = \\frac{1}{N}\\sum_{n=1}^N k(x-x_n;\\sigma^2)$\n",
        "\n",
        "$k(x-x_n;\\sigma^2) = \\exp\\left(\\frac{-\\|x-x_n\\|_2^2}{2\\sigma^2}\\right)$\n",
        "\n",
        "$\\hat{H}_2(X)=-\\log\\left(\\int \\hat{p}^2(x) dx \\right)= -\\log\\left(\\int \\hat{p}(x) \\hat{p}(x)dx\\right) = -\\log\\left(\\int \\frac{1}{N}\\sum_{n=1}^N k(x-x_n;\\sigma^2)\\frac{1}{N}\\sum_{m=1}^N k(x-x_m;\\sigma^2) dx\\right)$\n",
        "\n",
        "Applying convolution property for Gaussian functions:\n",
        "\n",
        "http://www.lucamartino.altervista.org/2003-003.pdf\n",
        "\n",
        "$\\boxed{\\hat{H}_2(X)= -\\log\\left(\\frac{1}{N^2}\\sum_{n=1}^N\\sum_{m=1}^N k(x_n-x_m;2\\sigma^2)\\right)}$\n",
        "\n",
        "Now, for $\\{x_n\\in\\mathbb{R}^P\\}_{n=1}^N$ (realted to $f(x)$) and $\\{x_m\\in\\mathbb{R}^P\\}_{m=1}^M$ (related to $g(x)$):\n",
        "\n",
        "$\\hat{H}_{CS}(f;g)=-\\log\\left(\\int \\hat{f}(x)\\hat{g}(x) dx \\right) = -\\log\\left(\\int \\frac{1}{N}\\sum_{n=1}^N k(x-x_n;\\sigma^2)\\frac{1}{M}\\sum_{m=1}^M k(x-x_m;\\sigma^2) dx\\right)$\n",
        "\n",
        "\n",
        "$\\boxed{\\hat{H}_{CS}(f;g)= -\\log\\left(\\frac{1}{NM}\\sum_{n=1}^N\\sum_{m=1}^M k(x_n-x_m;2\\sigma^2)\\right)}$\n",
        "\n",
        "\n",
        "Then:\n",
        "\n",
        "\n",
        "$$\\min_{\\hat{X}} H_2(\\tilde{X})+\\lambda D_{CS}(\\tilde{X}||X) = H_2(\\tilde{X})+\\lambda\\left(2 H_{CS}(\\tilde{X};X)-H_2(\\tilde{X})-H_2(X)\\right) $$\n",
        "\n",
        "$$\\min_{\\hat{X}} H_2(\\tilde{X})+\\lambda D_{CS}(\\tilde{X}||X) = H_2(\\tilde{X})+2 \\lambda H_{CS}(\\tilde{X};X)-\\lambda H_2(\\tilde{X})-\\lambda H_2(X) $$\n",
        "\n",
        "\n",
        "$$\\min_{\\hat{X}} (1-\\lambda)H_2(\\tilde{X})+2\\lambda H_{CS}(\\tilde{X};X)-\\lambda H_2(X) $$\n",
        "\n",
        "$-\\lambda H_2(X)$: constant w.r.t. $\\tilde{X}$\n",
        "\n",
        "PRI aims to minimize:\n",
        "\n",
        "\n",
        "$$\\boxed{\\min_{\\hat{X}} (1-\\lambda)H_2(\\tilde{X})+2\\lambda H_{CS}(\\tilde{X};X)} $$\n",
        "\n",
        "Applying Gaussian kernel-based parzen windows estimations:\n",
        "\n",
        "\n",
        "$$\\min_{\\hat{X}} (1-\\lambda)\\hat{H}_2(\\tilde{X})+2\\lambda \\hat{H}_{CS}(\\tilde{X};X)$$\n",
        "\n",
        "$$\\min_{\\hat{X}} (1-\\lambda)\\left(-\\log\\left(\\frac{1}{M^2}\\sum_{m=1}^M\\sum_{m'=1}^M k(\\tilde{x}_m-\\tilde{x}_{m'};2\\sigma^2)\\right)\\right)+2\\lambda\\left(-\\log\\left(\\frac{1}{MN}\\sum_{m=1}^M\\sum_{n=1}^N k(\\tilde{x}_m-x_n;2\\sigma^2)\\right)\\right)$$\n",
        "\n",
        "\n",
        "$\\tilde{x}_m,\\tilde{x}_{m'} \\in \\tilde{X}$, $x_n \\in X$\n",
        "\n",
        "## PRI Matrix Form\n",
        "\n",
        "$$\\boxed{\\min_{\\hat{X}} (1-\\lambda)\\left(-\\log\\left(\\frac{1}{M^2}1_M^\\top K_{\\tilde{X},\\tilde{X}} 1_M\\right)\\right)+2\\lambda\\left(-\\log\\left(\\frac{1}{MN}1_M^\\top K_{\\tilde{X},{X}} 1_N\\right)\\right)}$$\n",
        "\n",
        "$K_{\\tilde{X},{X}}=[k(\\tilde{x}_m-x_n;2\\sigma^2)]$\n",
        "\n",
        "$K_{\\tilde{X},\\tilde{X}}\\in [0,1]^{M\\times M},$ $K_{\\tilde{X},{X}}\\in [0,1]^{M\\times N}$\n",
        "\n",
        "$1_M$: all-ones column vector of size M.\n"
      ],
      "metadata": {
        "id": "K9GMQs_qriNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Matrix-based Renyi's Entropy](https://arxiv.org/abs/1211.2459)\n",
        "\n",
        "$S_\\alpha(A) = \\frac{1}{1-\\alpha}\\log\\left(tr(A^\\alpha)\\right)$\n",
        "\n",
        "$tr(A) = 1$\n",
        "\n",
        "$S_\\alpha(A,B) = S_\\alpha\\left(\\frac{A \\circ B}{tr(A \\circ B)}\\right) $\n",
        "\n",
        "$A,B \\succ 0;$ kernel matrices - gramm matrices\n",
        "\n",
        "$$I_\\alpha(X;\\hat{X}) = S_\\alpha(X) + S_\\alpha(\\hat{X}) - S_\\alpha(X,\\hat{X}) $$\n",
        "\n",
        "$X \\in \\mathbb{R}^{N \\times P}$; $\\hat{X}\\in \\mathbb{R}^{M \\times P}$; $M < N$\n",
        "\n",
        "\n",
        "$S_\\alpha(X)$ constant\n",
        "\n",
        "$$\\tilde{I}_\\alpha(X;\\hat{X}|\\lambda) = (1-\\lambda)S_\\alpha(\\hat{X}) - \\lambda S_\\alpha(X,\\hat{X}) $$\n",
        "\n",
        "$\\lambda \\in [0,1]$\n",
        "\n",
        "\n",
        "to think about it..."
      ],
      "metadata": {
        "id": "PPHcz20KN5Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests Pillow"
      ],
      "metadata": {
        "id": "GQMaUugjRGpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# URL of the image\n",
        "#image_url = 'https://a.storyblok.com/f/178900/640x360/776e917b43/3c62998ad933b2615c621eb613a9e99a1682968311_main.jpg/m/filters:quality(95)format(webp)'\n",
        "image_url = 'https://static.wikia.nocookie.net/dragonball/images/2/2e/Goku_Joven_Flashback.jpg/revision/latest?cb=20170809015919&path-prefix=es'\n",
        "# Send a GET request to the image URL\n",
        "response = requests.get(image_url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Open the image\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Display the image (if you're running this in a Jupyter notebook or similar environment)\n",
        "\n",
        "\n",
        "    # You can now use the 'image' object for further processing\n",
        "else:\n",
        "    print(\"Failed to retrieve the image. Status code:\", response.status_code)\n"
      ],
      "metadata": {
        "id": "dSkoi6K6RK2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "r02qSVcLRs05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_c = image.crop((450,50,1000,500))\n",
        "image_c"
      ],
      "metadata": {
        "id": "7JhjR0WGR8Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzoTZHlz6Yn-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_n = np.array(image_c)"
      ],
      "metadata": {
        "id": "phxfC95mS7gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to grayscale, as Canny edge detection requires grayscale images\n",
        "gray_image = cv2.cvtColor(image_n, cv2.COLOR_BGR2GRAY)\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "gray_image = cv2.dilate(gray_image, kernel, iterations=1)\n",
        "gray_image = cv2.erode(gray_image, kernel,  iterations=1)\n",
        "\n",
        "# Apply Canny edge detection\n",
        "# The arguments are the input image, and two thresholds: low and high\n",
        "# Play with these values to find the edges as per your requirement\n",
        "edges = cv2.Canny(gray_image, 225, 225)\n",
        "\n",
        "\n",
        "\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Edge Image')\n",
        "plt.show()\n",
        "plt.imshow(gray_image)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0XJBKSslTKXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "ths = 250\n",
        "y_, x_ = np.where(edges > ths)\n",
        "\n",
        "\n",
        "X = np.c_[x_,edges.shape[0]-y_]\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "#X = X[::5]\n",
        "plt.scatter(X[:,0],X[:,1])\n",
        "plt.show()\n",
        "print(X.shape,(edges>ths).sum())"
      ],
      "metadata": {
        "id": "nrQW5fpnT64e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exponential Quadratic kernel\n",
        "\n",
        "$ \\kappa(x, y) = \\varsigma^2 \\exp\\left(-\\frac{\\|x - y\\|^2_2}{2 \\sigma^2}\\right) $\n",
        "\n",
        "For simplicity: $\\varsigma = 1$\n",
        "\n",
        "# Parzen pdf estimation\n",
        "\n",
        "$\\hat{p}(x) = \\frac{1}{N}\\sum_{n=1}^N \\kappa(x, x_n)$\n",
        "\n",
        "$\\kappa(x, y)\\in[0,1]$\n",
        "\n"
      ],
      "metadata": {
        "id": "XuYc0JYbZyUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length_scale = 0.15\n",
        "\n",
        "ker = tfp.math.psd_kernels.ExponentiatedQuadratic(length_scale=length_scale)\n",
        "Kx = ker.matrix(X, X)\n",
        "plt.imshow(Kx.numpy())\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fvl2YgqQ7Aoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px = (1/X.shape[0])*Kx.numpy().dot(np.ones((X.shape[0],1))).ravel()\n",
        "plt.bar(np.arange(0,X.shape[0]),px)\n",
        "plt.ylabel('p(x)')\n",
        "plt.xlabel('x')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(X[:,0],X[:,1],c = px)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ORh0LNx27BSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix-based Renyi's Entropy Principle Relevant Information\n",
        "\n"
      ],
      "metadata": {
        "id": "rkyscIbbcm96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#uniform init\n",
        "def PRI_init(X,M,por_=0.05):\n",
        "    xmin_values = tf.constant(list(X.min(axis=0)-por_*X.max(axis=0)),dtype = \"float32\")\n",
        "    xmax_values = tf.constant(list(X.max(axis=0)+por_*X.max(axis=0)),dtype = \"float32\")\n",
        "\n",
        "    rows = M\n",
        "    cols = X.shape[1]  # Number of columns\n",
        "\n",
        "    random_tensor_scaled = tf.math.multiply(tf.random.uniform(shape=(rows, cols), minval=0, maxval=1),\n",
        "                                            tf.repeat(tf.transpose(xmax_values[:, tf.newaxis] - xmin_values[:, tf.newaxis]),rows,axis=0))\n",
        "\n",
        "    # Add the minimum values to each row\n",
        "    return random_tensor_scaled +  tf.repeat(tf.transpose(xmin_values[:, tf.newaxis]),rows,axis=0)\n",
        "\n",
        "Xh = PRI_init(X,M=300,por_=0.05)\n",
        "Xh.shape"
      ],
      "metadata": {
        "id": "KyK-wj-Bbq0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xh_ =  Xh.numpy()\n",
        "plt.scatter(X[:,0],X[:,1],c = 'b')\n",
        "plt.scatter(Xh_[:,0],Xh_[:,1],c = 'r')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qUCAIu3WnAnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRI Matrix Form\n",
        "\n",
        "$$\\boxed{\\min_{\\hat{X}} (1-\\lambda)\\left(-\\log\\left(\\frac{1}{M^2}1_M^\\top K_{\\tilde{X},\\tilde{X}} 1_M\\right)\\right)+2\\lambda\\left(-\\log\\left(\\frac{1}{MN}1_M^\\top K_{\\tilde{X},{X}} 1_N\\right)\\right)}$$"
      ],
      "metadata": {
        "id": "0OqzppxNvtxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def pri_loss(Xh,Xt,ker,lam_):\n",
        "  Khh = ker.matrix(Xh, Xh)\n",
        "  Khx = ker.matrix(Xh, Xt)\n",
        "  return (1.0-lam_)*(-tf.math.log(tf.math.reduce_mean(Khh)))+(2.0*lam_)*(-tf.math.log(tf.math.reduce_mean(Khx)))"
      ],
      "metadata": {
        "id": "jr0V5MRhvaXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorflow data\n",
        "M = 500\n",
        "Xh = PRI_init(X,M=M,por_=0.025)\n",
        "Xt = tf.convert_to_tensor(X,dtype=tf.float32)\n",
        "lam_ = 0.95\n",
        "lam_ = tf.constant(lam_,dtype=tf.float32)\n",
        "\n",
        "#kernel\n",
        "length_scale = 0.05\n",
        "ker = tfp.math.psd_kernels.ExponentiatedQuadratic(length_scale=length_scale)"
      ],
      "metadata": {
        "id": "8QfV0dVBy4St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_decay_lr(initial_lr, decay_rate, epoch):\n",
        "    return initial_lr * decay_rate ** epoch"
      ],
      "metadata": {
        "id": "RVA0nGLhiJks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xh_ =  Xh.numpy()\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.scatter(X[:,0],X[:,1],c = 'b',s=2)\n",
        "plt.scatter(Xh_[:,0],Xh_[:,1],c = 'r',s=10,marker='x')\n",
        "plt.show()\n",
        "# Custom training loop\n",
        "eta0 = 1e-1\n",
        "batch_size = 256\n",
        "epochs = 50\n",
        "decay_rate = 0.95\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    eta = exp_decay_lr(eta0, decay_rate=decay_rate, epoch=epoch)\n",
        "    for x_batch in tf.data.Dataset.from_tensor_slices(Xt).shuffle(buffer_size=1024).batch(batch_size):\n",
        "\n",
        "      with tf.GradientTape() as g:\n",
        "        g.watch(Xh)\n",
        "        pri_loss_ = pri_loss(Xh,x_batch,ker,lam_)\n",
        "      grad_ = g.gradient(pri_loss_, Xh)\n",
        "      Xh = Xh -eta*grad_\n",
        "    print(f'Loss: {pri_loss_.numpy()} MeanGrad: {tf.math.reduce_mean(grad_,axis=0).numpy()}')\n",
        "\n",
        "    Xh_ =  Xh.numpy()\n",
        "    gradN = -10*eta*grad_.numpy()\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.scatter(X[:,0],X[:,1],c = 'b',s=1)\n",
        "    plt.scatter(Xh_[:,0],Xh_[:,1],c = 'r',s=10,marker='x')\n",
        "    plt.quiver(Xh_[:,0],Xh_[:,1], gradN[:,0], gradN[:,1], color='g', scale=1, scale_units='xy', angles='xy', label='Gradient Vectors')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bEucgi8zouu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YjLnTvLP1tyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tareas Luker - Sofia y Juan Lugo\n",
        "\n",
        "\n",
        "## Unsupervised Deep Embedding for Clustering Analysis\n",
        "\n",
        "https://proceedings.mlr.press/v48/xieb16.pdf\n",
        "\n",
        "https://github.com/HaebinShin/dec-tensorflow\n",
        "\n",
        "\n",
        "## Tareas Sofia:\n",
        "\n",
        "Revisar matemática PRI\n",
        "\n",
        "Revisar Paper Unsupervised Deep Embedding for Clustering Analysis\n",
        "\n",
        "Implementar DEC según github compartido y aplicar sobre experimento de goku y sobre Fashion Mnist\n",
        "\n",
        "## Tareas Juan Lugo\n",
        "\n",
        "Revisar modelo tabnet\n",
        "\n",
        "https://paperswithcode.com/method/tabnet\n",
        "\n",
        "Revisar implementaciones sobre keras\n",
        "\n",
        "https://github.com/jeyabbalas/tabnet\n",
        "\n",
        "Aplicar sobre base de datos fifa19 curso aprendizaje de máquina para luego aplicar a Luker\n",
        "\n",
        "## Objetivo luker\n",
        "\n",
        "- Unir DCE/PRI sofia con Tabnet Lugo, con modelo generativo para lidear con generación de propiedades físico químicas desde espacio latente anotadores\n",
        "\n",
        "## Tareas sofia y lugo\n",
        "\n",
        "Revisar focal loss para lidear con datos desbalanceados\n",
        "\n",
        "https://paperswithcode.com/method/focal-loss"
      ],
      "metadata": {
        "id": "D8JWligOoQ7m"
      }
    }
  ]
}