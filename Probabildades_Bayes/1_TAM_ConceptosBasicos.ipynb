{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP7AtkWLLih9aM9naR2IN8t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalvarezme/AprendizajeMaquina/blob/main/Probabildades_Bayes/1_TAM_ConceptosBasicos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios Capítulo 1 - Teoría de Aprendizaje de Máquina\n",
        "\n",
        "Elaborado por: Andrés Marino Álvarez Meza, amalvarezme@unal.edu.co"
      ],
      "metadata": {
        "id": "9q_77PYmamwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio regresores\n",
        "\n",
        " - Genere datos sintéticos a partir de un tono. senoidal, contaminado con ruido blanco Gaussiano para $SNR_{dB}=\\{1,2,5,10\\} [dB].$\n",
        "\n",
        " - Entrene y pruebe los modelos de regresión por mínimos cuadrados (regularizado con norma L2), log verosimilitud y Máximo a posteriori (prior y ruido Gaussianos), utilizando el $80\\%$ de los datos para entrenar y el $20\\%$ para evaluar.\n",
        "\n",
        "## Relación señal ruido - Signal to Noise Ratio (SNR)\n",
        "\n",
        "\n",
        "$P_x = \\frac{1}{T}\\int |x(t)|^2 dt$ : potencia de la señal.\n",
        "\n",
        "$P_\\eta = \\frac{1}{T}\\int |\\eta(t)|^2 dt$ : potencia del ruido.\n",
        "\n",
        "La SNR se define como:\n",
        "\n",
        "$SNR = \\frac{P_x}{P_\\eta}$\n",
        "\n",
        "En decibeles:\n",
        "\n",
        "$SNR_{dB}  = 10\\log_{10}\\left(\\frac{P_x}{P_\\eta}\\right) \\quad [dB]$\n",
        "\n",
        "Para pasar de $SNR_{dB}$ a SNR:\n",
        "\n",
        "$SNR = 10^{\\frac{SNR_{dB}}{10}} =  \\frac{P_x}{P_\\eta}$\n",
        "\n",
        "\n",
        "Para el caso de ruido blanco Guassiano:\n",
        "\n",
        "$\n",
        "\\eta \\sim p(\\eta) = \\mathscr{G}(\\eta|0,\\sigma_\\eta^2)\n",
        "$\n",
        "\n",
        "Dado que $\\mu_\\eta = 0$:\n",
        "\n",
        "$\\sigma_\\eta^2 = \\mathbb{E}\\{(\\eta-\\mu_\\eta)^2\\} = \\mathbb{E}\\{\\eta^2\\} $\n",
        "\n",
        "Utilizando estimador de media muestral:\n",
        "\n",
        "$\\sigma_{\\eta}^{2}=\\frac{1}{N}\\sum_\\limits{\\eta} \\eta^2$\n",
        "\n",
        "Entonces:\n",
        "\n",
        "$\\sigma_{\\eta}^{2} = P_\\eta = \\frac{P_x}{SNR} =  \\frac{P_x}{ 10^{\\frac{SNR_{dB}}{10}}}$"
      ],
      "metadata": {
        "id": "kl5k3pxlaoKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#función cálculo varianza del ruido a partir del snr dB\n",
        "def var_snr(x,snrdB): #x vector de datos (señal), snrdB SNR en dB\n",
        "    Px = np.mean(x**2)#estimador potencia media de la señal\n",
        "    return Px/(10**(snrdB/10))"
      ],
      "metadata": {
        "id": "xWUiwuZYBL7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se construyen los datos a partir del modelo:\n",
        "\n",
        "$t_n = A\\sin(2\\pi F_o x_n) + \\eta_n$\n",
        "\n",
        "con:\n",
        "\n",
        "$x_n \\in [0,T_o]$\n",
        "\n",
        "$T_o=1/F_o$\n",
        "\n",
        "$\\eta \\sim \\mathscr{G}(\\eta_n|0,\\sigma^2_\\eta)$"
      ],
      "metadata": {
        "id": "MF-eWzE1Cts5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datos simulados\n",
        "Fo = 60 #frecuencia fundamental señal cos\n",
        "A = 10 # amplitud de la señal\n",
        "To = 1/Fo #periodo fundamental\n",
        "Fs = 100*Fo #frecuencia muestreo según nyquist Fs >= 2 Fo\n",
        "X = np.arange(0,To,1/Fs) #vector de entrada en un periodo con pasos según período de muestreo\n",
        "\n",
        "snrdB = 10 #ruido según SNR dB\n",
        "#señal limpia - objetivo\n",
        "tt = A*np.sin(2*np.pi*Fo*X)\n",
        "#modelo con función sinoidal contaminada con ruido Gaussiano\n",
        "t = A*np.sin(2*np.pi*Fo*X) + np.sqrt(var_snr(tt,snrdB))*np.random.randn(len(X))\n",
        "\n",
        "X = X.reshape(-1,1)#filas = realizaciones-muestras\n",
        "t = t.reshape(-1,1)\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t^*$')\n",
        "plt.scatter(X,t,c='b',label='$t$')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P6KQ8DSDCc4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solución por mínimos cuadrados:\n",
        "\n",
        "Se asume mapeo $\\phi:\\mathbb{R}^P\\to\\mathbb{R}^Q$, con $Q\\geq P.$\n",
        "\n",
        "Dado el conjunto de datos $\\{\\phi(\\mathbf{x}_n) \\in \\mathbb{R}^Q, t_n \\in \\mathbb{R}\\}_{n=1}^N,$ podemos definir el modelo lineal:\n",
        "\n",
        "$t_n = \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top + \\eta_n$\n",
        "\n",
        "$\\mathbf{w}\\in\\mathbb{R}^Q$\n",
        "\n",
        "## Estimador por mínimos cuadrados:\n",
        "\n",
        "El estimador generalizado de mínimos cuadrados con regularización L2 (también conocido como modelo lineal rígido - linear ridge regression), se puede plantear como:\n",
        "\n",
        "$$\\mathbf{w}_{MC2} = \\arg\\min_{\\mathbf{w}} \\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2 + \\lambda \\|\\mathbf{w}\\|^2_2$$\n",
        "\n",
        "con:\n",
        "\n",
        "$\\mathbf{t} = [t_1,t_2,\\cdots,t_n]^\\top\\in\\mathbb{R}^N$\n",
        "\n",
        "$\\pmb{\\Phi}=[\\phi(\\mathbf{x}_1),\\phi(\\mathbf{x}_2),\\cdots,\\phi(\\mathbf{x}_N)]^\\top\\in\\mathbb{R}^{N\\times Q}$\n",
        "\n",
        "$\\lambda\\in\\mathbb{R}^{+}$\n",
        "\n",
        "Derivando e igualando a cero para encotrar el mínimo de la función de costo, tenemos que:\n",
        "\n",
        "$$\\mathbf{w}_{mc} = \\left(\\pmb{\\Phi}^\\top \\pmb{\\Phi}+\\lambda\\mathbf{I_Q}\\right)^{-1}\\pmb{\\Phi}^\\top \\mathbf{t}$$\n",
        "\n",
        "$\\mathbf{I}_Q$: matriz identidad de tamaño $Q$.\n",
        "\n"
      ],
      "metadata": {
        "id": "x-aH4dlyFnxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solución min cuadrados regularizados\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "#generación representación polinomial\n",
        "#desde la libreria sklearn\n",
        "Q = 4#grado del polinomio\n",
        "phiQ = PolynomialFeatures(degree=Q)\n",
        "Phi = phiQ.fit_transform(X)#representar datos desde polinomio\n",
        "\n",
        "#particionar datos\n",
        "rs = ShuffleSplit(n_splits=1, random_state=0, test_size=0.2)\n",
        "for i, (train_i, test_i) in enumerate(rs.split(X)):\n",
        "   print(i)\n",
        "\n",
        "\n",
        "#regresor\n",
        "lambdaR = 1e-15#hiperparámetro de regularización\n",
        "reg_mc = Ridge(alpha=lambdaR)\n",
        "\n",
        "train_i = np.sort(train_i)\n",
        "test_i = np.sort(test_i)\n",
        "\n",
        "reg_mc.fit(Phi[train_i],t[train_i])\n",
        "\n",
        "t_mc = reg_mc.predict(Phi[test_i])\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t^*$')\n",
        "plt.scatter(X,t,c='b',label='$t$')\n",
        "plt.plot(X[test_i],t_mc,c='g',label='$t_{mcr}$')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.stem(reg_mc.coef_[0])\n",
        "plt.ylabel('pesos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aGPjIlB5OFfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementando solución por svd"
      ],
      "metadata": {
        "id": "5VRCSIiWbUkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regsvd(Phi,t,lambdaR=0,tol=1e-16):\n",
        "  S = Phi.T.dot(Phi) + lambdaR*np.eye(Phi.shape[1])\n",
        "  val,vec = np.linalg.eig(S)\n",
        "  print(val.shape,vec.shape)\n",
        "  ind = val > tol #valores propios mayores a 0\n",
        "  Sinv = vec[:,ind].dot(np.diag(1/val[ind])).dot(vec[:,ind].T)\n",
        "  return Sinv.dot(Phi.T.dot(t)),val\n"
      ],
      "metadata": {
        "id": "_rfLTOf0bWqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wml,val = regsvd(Phi[train_i],t[train_i],lambdaR=lambdaR)\n",
        "\n",
        "t_mc = Phi[test_i].dot(wml)\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t^*$')\n",
        "plt.scatter(X,t,c='b',label='$t$')\n",
        "plt.plot(X[test_i],t_mc,c='g',label='$t_{mcr}$')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.stem(val)\n",
        "plt.ylabel('eigenvalue')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.stem(wml)\n",
        "plt.ylabel('pesos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zvF6WZNc4lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictiva desde máxima verosimilitud\n",
        "\n",
        "Para el caso de ruido blanco Gaussiano, tenemos que:\n",
        "\n",
        "$\\eta_n \\sim p(\\eta_n) = \\mathscr{G}(\\eta_n|0,\\sigma_\\eta^2)$\n",
        "\n",
        "con:\n",
        "\n",
        "$t_n = \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top + \\eta_n$\n",
        "\n",
        "$\\eta_n = t_n - \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top$\n",
        "\n",
        "Por lo tanto:\n",
        "\n",
        "$p(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2) = \\mathscr{G}(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2)$\n",
        "\n",
        "Podemos encontrar los pesos y la varianza maximizando el log-verosimilitud:\n",
        "\n",
        "$$\\mathbf{w}_{ML} = \\arg\\max_{\\mathbf{w},\\sigma_\\eta^2} \\log\\left(\\prod_{n=1}^N\\mathscr{G}(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2)\\right)$$\n",
        "\n",
        "Asumiendo datos i.i.d.:\n",
        "\n",
        "$$\\mathbf{w}_{ML},\\sigma_{ML}^2 = \\arg\\max_{\\mathbf{w},\\sigma_\\eta^2} -\\frac{N}{2}\\log(2\\pi)-\\frac{N}{2}\\log(\\sigma_\\eta^2)-\\frac{1}{2\\sigma^2}\\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2$$\n",
        "\n",
        "Derivando respecto a las variables de interés, e igualando a 0:\n",
        "\n",
        "$$\\sigma^2_{ML} = \\frac{1}{N}\\sum_\\limits{n=1}^N\\left(t_n-\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top\\right)^2$$\n",
        "\n",
        "$$\\mathbf{w}_{ML} = \\left(\\pmb{\\Phi}^\\top \\pmb{\\Phi}\\right)^{-1}\\pmb{\\Phi}^\\top \\mathbf{t}$$\n",
        "\n",
        "\n",
        "La fdp predictiva, para un nuevo dato $\\mathbf{x}_*$, se puede estimar como:\n",
        "\n",
        "$$p(t_*|\\mathbf{x}_*,\\mathbf{t},\\pmb{\\Phi},\\mathbf{w}_{ML},\\sigma^2_{ML})=\\mathscr{G}(t_*|\\phi(\\mathbf{x}_*)\\mathbf{w}_{ML}^\\top,\\sigma_{ML}^2)$$"
      ],
      "metadata": {
        "id": "kGpHK3jvfo-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gráfica estimación con predictiva en ML:\n",
        "var_ml = (np.linalg.norm(t[train_i]-reg_mc.predict(Phi[train_i]))**2)/len(t[train_i])\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X,tt,c='r',label='$t$')\n",
        "plt.scatter(X,t,c='b',label='$t+\\eta$')\n",
        "plt.plot(X[test_i],t_mc,c='g',label='$t_{*}$')\n",
        "plt.fill_between(X[test_i].ravel(), t_mc.ravel() - 1.96*np.sqrt(var_ml)*np.ones(len(t_mc)),\n",
        "                t_mc.ravel() + 1.96*np.sqrt(var_ml)*np.ones(len(t_mc)), alpha=0.2)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wyqcgzl8jubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Teorema del límite central\n",
        "\n",
        "Sea $x_n \\sim p(x_n)$ una variable aleatoria con fdp $p(x_n)$.\n",
        "\n",
        "La combinación:\n",
        "\n",
        "$a_0 x_0+a_1x_1+a_2x_2+ \\cdots a_N x_N \\sim \\mathscr{G}(\\sum_n a_n x_n | \\mu_,\\sigma^2)$\n",
        "\n",
        "Siendo $\n",
        "\\mathfrak{G}$ una fdp Gaussiana.\n",
        "## Ejemplo\n",
        "\n",
        "Sea $x\\sim \\mathscr{U}(x|0,1)$ una variable aleatoria con fdp Uniforme. Mediante una simulación de Monte-Carlo de 1000 repeticiones, encuentre la estimación por histograma de la fdp de la media muestral $x$, con base al muestreo desde la fdp Uniforme con $N\\in\\{1.2.10\\}$ datos."
      ],
      "metadata": {
        "id": "genhr8rEReJl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mofc88lCRdUq"
      },
      "outputs": [],
      "source": [
        "#simulación del teorema del límite central\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#posibles cantidades de datos\n",
        "N = np.array([1,2,10])\n",
        "#repeticiones del experimento - simulación de monte carlo\n",
        "M = 1000\n",
        "mlc = np.zeros((M,len(N)))\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "for i in range(len(N)):#recorrer cantidad de muestras\n",
        "    for j in range(M): #recorrer iteraciones de monte carlo\n",
        "        xdata = np.random.rand(N[i])#simulamos datos desde una fdp uniforme\n",
        "        mlc[j,i] = xdata.mean() #estimación media muestral x\n",
        "    plt.hist(mlc[:,i],bins=8, label='N='+str(N[i]),density=True, alpha=0.5) #graficar histograma\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('$\\hat{\\mu}(x)$')\n",
        "plt.ylabel('$\\hat{p}(\\hat{\\mu}(x))$')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guassianas condicionales y máximo a posteriori\n",
        "\n",
        "Para resolver el regresor Bayesiano completo, necesitamos encontrar la probabilidad condicional dado una probabilidad conjunta Gaussiana.\n",
        "\n",
        "Para el caso del máximo a posteriori, desde el teorema de Bayes, tenemos que (se simplifica el modelo en función de la salida y los pesos para facilitar la notación):\n",
        "\n",
        "$p(\\mathbf{t},\\mathbf{w})=p(\\mathbf{w},\\mathbf{t})$\n",
        "\n",
        "$p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w})=p(\\mathbf{w}|\\mathbf{t})p(\\mathbf{t})$\n",
        "\n",
        "El posterior $p(\\mathbf{w}|\\mathbf{t})$ se puede encontrar como:\n",
        "\n",
        "$$p(\\mathbf{w}|\\mathbf{t})=\\frac{p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathbf{t})}$$\n",
        "\n",
        "con evidencia:\n",
        "\n",
        "\n",
        "$p(\\mathbf{t})=\\int p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w}) d\\mathbf{w}$\n",
        "\n",
        "Para el caso de ruido y pesos modelados mediante fdp Gaussinas:\n",
        "\n",
        "$t_n = \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top + \\eta_n$\n",
        "\n",
        "$\\eta_n \\sim p(\\eta_n)= \\mathscr{G}(\\eta_n|0,\\sigma_\\eta^2)$\n",
        "\n",
        "$\\eta_n = t_n - \\phi(\\mathbf{x}_n)\\mathbf{w}^\\top$\n",
        "\n",
        "Por lo tanto:\n",
        "\n",
        "$p(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2) = \\mathscr{G}(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2)$$\n",
        "\n",
        "Además:\n",
        "\n",
        "$p(\\mathbf{w})= \\mathscr{G}(\\mathbf{w}|0,\\sigma_w^2\\mathbf{I}_Q)$\n",
        "\n",
        "El modelo por máximo a-posteriori, simplifica la relación de Bayes mediante la proporcionalidad:\n",
        "\n",
        "$p(\\mathbf{w}|\\mathbf{t}) \\propto p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w})$\n",
        "\n",
        "Por consiguiente, asumiendo datos i.i.d.:\n",
        "\n",
        "$$\\mathbf{w}_{MAP} = \\arg\\max_{\\mathbf{w}} \\log\\left(\\prod_{n=1}^N\\mathscr{G}\\left(t_n|\\phi(\\mathbf{x}_n)\\mathbf{w}^\\top,\\sigma_\\eta^2\\right)\\prod_{q=1}^Q \\mathscr{G}({w}_q|0,\\sigma_w^2)\\right)$$\n",
        "\n",
        "Asumiendo datos i.i.d.:\n",
        "\n",
        "$$\\mathbf{w}_{MAP} = \\arg\\max_{\\mathbf{w}} -\\frac{1}{2\\sigma_\\eta^2}\\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2 - -\\frac{1}{2\\sigma_w^2}\\|\\mathbf{w}\\|^2_2$$\n",
        "\n",
        "Teniendo en cuenta que los factores de escala no modifican el punto mínimo/máximo en la optmización, podemos factorizar el problema equivalente MAP como:\n",
        "\n",
        "\n",
        "$$\\mathbf{w}_{MAP} = \\arg\\min_{\\mathbf{w}} \\|\\mathbf{t}-\\pmb{\\Phi}\\mathbf{w}^\\top\\|^2_2 + \\frac{\\sigma^2_\\eta}{\\sigma_w^2}\\|\\mathbf{w}\\|^2_2$$\n",
        "\n",
        "Bajo estas suposiciones, el problema de optimización de MAP asumiendo ruido y prior Gaussianos, es equivalente a la optimización de mínimos cuadrados regularizados con $\\lambda=\\frac{\\sigma^2_\\eta}{\\sigma_w^2}.$\n",
        "\n",
        "Ahora, analizando un modelo lineal Gaussiano desde la conjunta:\n",
        "\n",
        "\n",
        "$\\mathbf{z} = [\\mathbf{x}_a,\\mathbf{x}_b] \\sim \\mathscr{G}(\\mathbf{z}|\\pmb{\\mu},\\mathbf{\\Sigma})$\n",
        "\n",
        "tenemos que:\n",
        "\n",
        "$p(\\mathbf{x}_a|\\mathbf{x}_b)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a|b},\\mathbf{\\Sigma}_{a|b})$\n",
        "\n",
        "\n",
        "donde:\n",
        "\n",
        "$\\pmb{\\mu}_{a|b}=\\pmb{\\mu}_{a}+\\mathbf{\\Sigma}_{ab}\\mathbf{\\Sigma}_{bb}^{-1}(\\mathbf{x}_b - \\pmb{\\mu}_b)$\n",
        "\n",
        "$\\mathbf{\\Sigma}_{a|b} = \\mathbf{\\Sigma}_{aa}-\\mathbf{\\Sigma}_{ab}\\mathbf{\\Sigma}_{bb}^{-1}\\mathbf{\\Sigma}_{ba}$\n",
        "\n",
        "y\n",
        "\n",
        "$p(\\mathbf{x}_a)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a},\\mathbf{\\Sigma}_{aa})$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OyO5m3A4-vDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo:\n",
        "\n",
        "Sea la variable aleatoria $\\mathbf{z} = [x_a,x_b]\\sim \\mathscr{G}(\\mathbf{z}|\\pmb{\\mu},\\mathbf{\\Sigma})$, con:\n",
        "\n",
        "$$\\pmb{\\mu} = [\\mu_a,\\mu_b] = [0.5,0.2]$$\n",
        "\n",
        "$$\\pmb{\\Sigma}= \\begin{bmatrix} \\sigma_a^2 & \\sigma_{ab}\\\\ \\sigma_ba & \\sigma^2_{b}\\end{bmatrix} = \\begin{bmatrix} 0.8 & 0.3\\\\ 0.3 & 0.6\\end{bmatrix} $$\n",
        "\n",
        "\n",
        "Encuentre y grafique $p(\\mathbf{x}_a)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a},\\mathbf{\\Sigma}_{aa})$ y $p(\\mathbf{x}_a|\\mathbf{x}_b)=\\mathscr{G}(\\mathbf{x}_a|\\pmb{\\mu}_{a|b},\\mathbf{\\Sigma}_{a|b})$"
      ],
      "metadata": {
        "id": "xejKIJlLUo6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import multivariate_normal as mn\n",
        "#simulamos la fdp conjunta\n",
        "N = 100\n",
        "muC = np.array([0.5,0.2])\n",
        "SigmaC = np.array([[0.8,0.3],[0.3,0.6]])\n",
        "pdfC = mn(muC, SigmaC)\n",
        "Xd = pdfC.rvs(size=N)\n",
        "pC = pdfC.pdf(Xd)\n",
        "\n",
        "#meshgrid contornos\n",
        "h = 0.02\n",
        "x_min, x_max = Xd[:, 0].min() - np.std(Xd[:, 0]), Xd[:, 0].max() + np.std(Xd[:, 0])\n",
        "y_min, y_max = Xd[:, 1].min() - np.std(Xd[:, 1]), Xd[:, 1].max() + np.std(Xd[:, 1])\n",
        "xx, yy = np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)\n",
        "\n",
        "X = np.linspace(x_min, x_max, round(0.5*N))\n",
        "Y = np.linspace(y_min, y_max, round(0.5*N))\n",
        "X, Y = np.meshgrid(X, Y)\n",
        "\n",
        "\n",
        "# Pack X and Y into a single 3-dimensional array\n",
        "pos = np.empty(X.shape + (2,))\n",
        "pos[:, :, 0] = X\n",
        "pos[:, :, 1] = Y\n",
        "\n",
        "# evaluar pdf conjunta\n",
        "Z = pdfC.pdf(pos)\n",
        "\n",
        "#x_b = 2\n",
        "xb = 2\n",
        "#contornos\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.contour(X, Y, Z,levels=20)\n",
        "#scatter\n",
        "plt.scatter(Xd[:,0],Xd[:,1],c='r')\n",
        "plt.plot(np.linspace(x_min,x_max,50),xb*np.ones((50,1)),c='g')\n",
        "plt.grid()\n",
        "plt.xlabel('$x_a$')\n",
        "plt.ylabel('$x_b$')\n",
        "plt.title('$p(x_a,x_b)$')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#probabilidad marginal de x_a\n",
        "mu_a = 0.5\n",
        "Sigma_a = 0.8\n",
        "pdf_a = mn(mu_a, Sigma_a)\n",
        "X_a = np.linspace(1.25*x_min,1.25*x_max,N)\n",
        "p_a = pdf_a.pdf(X_a)\n",
        "\n",
        "#probabilidad condicional x_a | x_b = 2\n",
        "mu_b = 0.2\n",
        "Sigma_ab = 0.3\n",
        "Sigma_ba = Sigma_ab\n",
        "Sigma_b = 0.6\n",
        "\n",
        "mu_alb = mu_a+Sigma_ab*Sigma_b**(-1)*(xb - mu_b)\n",
        "Sigma_alb = Sigma_a-Sigma_ab*Sigma_b**(-1)*Sigma_ba\n",
        "pdf_alb = mn(mu_alb, Sigma_alb)\n",
        "p_alb = pdf_alb.pdf(X_a)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(X_a,p_a,label='$p(x_a)$')\n",
        "plt.plot(X_a,p_alb,label='$p(x_a|x_b=2)$')\n",
        "plt.xlabel('$x_a$')\n",
        "plt.ylabel('fdp')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wPnLSd3IgXwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KK4BAVy0j5zi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}